# ─── Intercom API ─────────────────────────────────────────────

# Token de acceso de Intercom (Bearer token)
INTERCOM_ACCESS_TOKEN=your_intercom_access_token_here

# ID de la carpeta de Intercom de donde exportar artículos (opcional)
INTERCOM_FOLDER_ID=your_folder_id_here

# URL base de la API de Intercom (opcional, por defecto usa la pública)
INTERCOM_API_BASE=https://api.intercom.io

# ─── Notion Sync ──────────────────────────────────────────────

# Token de integración de Notion (secret_xxx)
# Se obtiene en https://www.notion.so/my-integrations
NOTION_TOKEN=secret_xxx

# ID de la página padre en Notion donde se crearán los artículos
# Asegúrate de compartir la página con tu integración (... → Add connections)
NOTION_PARENT_PAGE_ID=xxx

# Directorio con los .md a sincronizar (relativo a la raíz del repo)
# Por defecto: articles
ARTICLES_PATH=articles

# ─── Changelog Pipeline ──────────────────────────────────────

# Repo del SaaS a monitorizar (formato: owner/name)
# Ejemplo: acme/enginy
SAAS_REPO=owner/repo

# Proveedor LLM: openai | anthropic | ollama
# Solo se leen las variables del proveedor seleccionado
LLM_PROVIDER=anthropic

# ─── OpenAI (si LLM_PROVIDER=openai) ─────────────────────────
# OPENAI_API_KEY=sk-xxx
# OPENAI_MODEL=gpt-4o-mini
# OPENAI_BASE_URL=                  # Opcional, para proxies compatibles

# ─── Anthropic (si LLM_PROVIDER=anthropic) ────────────────────
ANTHROPIC_API_KEY=sk-ant-xxx
ANTHROPIC_MODEL=claude-opus-4-20250514
# Modelos recomendados: claude-sonnet-4-20250514 (equilibrado), claude-opus-4-20250514 (máxima calidad)

# ─── Ollama (si LLM_PROVIDER=ollama) ──────────────────────────
# OLLAMA_MODEL=llama3
# OLLAMA_BASE_URL=http://localhost:11434/v1

# ─── Cloudinary ──────────────────────────────────────────────

# Credenciales para subir imágenes a Cloudinary (npm run cloudinary)
# Se obtienen en https://console.cloudinary.com/settings/api-keys
CLOUDINARY_CLOUD_NAME=your_cloud_name
CLOUDINARY_API_KEY=your_api_key
CLOUDINARY_API_SECRET=your_api_secret
